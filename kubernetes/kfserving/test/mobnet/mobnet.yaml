apiVersion: "serving.kubeflow.org/v1alpha2"
kind: "InferenceService"
metadata:
  name: "mobnet"
spec:
  default:
    predictor:
      tensorflow:
        storageUri: "gs://suminseo-datasets/KFServing/model-1.15.2/sm-model/"
        resources:
          requests:
            cpu: 0.1
            memory: 2Gi
          limits:
            memory: 2Gi
    explainer:
      alibi:
        type: AnchorImages
        storageUri: "gs://suminseo-datasets/KFServing/explainer-v0.3.2/"
        config:
          batch_size: "1"
        resources:
          requests:
            cpu: 0.2
            memory: 2Gi
          limits:
            memory: 2Gi